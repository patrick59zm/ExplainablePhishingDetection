Dataframes in data/raw. Are of the form they are downlaoded in.
In data/preprocessed they have labels: text, p_label, g_label, origin
text corresponds to the feature on which we aim to classify
p_label indicates phishing  (1 if true)
g_label indicates if generated (1 if true)
dataset corresponds to origin dataset
0 : https://www.kaggle.com/datasets/subhajournal/phishingemails

get data from: https://polybox.ethz.ch/index.php/s/oS8Ej54GpfpLsP6


Origin  Dataset Name           typeFile         link
------  -------------          -----            -------------------------
Origin  Dataset Name                        Type     Source
------  ---------------------------------  -------  ---------------------------------------------------------
0       phishing_dataset.csv               phis     https://www.kaggle.com/datasets/subhajournal/phishingemails
1       jose private                       phis     (not used – mails unprocessable)
3       ceas-08.csv                        phis     https://figshare.com/articles/dataset/Seven_Phishing_Email_Datasets/25432108
4       enron.csv                          phis     https://figshare.com/articles/dataset/Seven_Phishing_Email_Datasets/25432108
5       ling.csv                           phis     https://figshare.com/articles/dataset/Seven_Phishing_Email_Datasets/25432108
6       assassin.csv                       phis     https://figshare.com/articles/dataset/Seven_Phishing_Email_Datasets/25432108
7       trec-05.csv                        phis     https://figshare.com/articles/dataset/Seven_Phishing_Email_Datasets/25432108
8       trec-06.csv                        phis     https://figshare.com/articles/dataset/Seven_Phishing_Email_Datasets/25432108
9       trec-07.csv                        phis     https://figshare.com/articles/dataset/Seven_Phishing_Email_Datasets/25432108
10      spam.csv                           phis     https://www.kaggle.com/datasets/shantanudhakadd/email-spam-detection-dataset-classification
11      combined_..._generated.csv         mixed    https://www.kaggle.com/datasets/francescogreco97/human-llm-generated-phishing-legitimate-emails
12      autextification_en_combined.csv    gene     https://huggingface.co/datasets/symanto/autextification2023
13      ai_phishing_emails.csv             mixed    https://people.cs.ksu.edu/~lshamir/data/ai_phishing/




create_train_test_sets.py
(not a markdown file) so that you can run it directly or via the provided shell command (for example, using:
    bash data/run_dataset_split.sh --output_name trial_one.

This script creates custom train/test sets from a combined CSV. It supports the following arguments (see the README text for details):

•Required argument:
    output_name (str): Base name for the output files. Two files will be generated (train and test).

•Optional arguments:
    num_rows (int): Limit the number of rows in the final dataset (after filtering).
    origins (list of int): Filter only specific datasets using their origin IDs.(default: all)
    data_type (str): Type of data to include, with options:
        – phishing: Only samples with a non-null p_label (phishing)
        – machine: Only samples with a non-null g_label (machine-generated)
        – mixed: Only samples where both p_label and g_label exist (but balance is enforced only on p_label)
        – any: No filtering by label type (default)
    test_size (float): Proportion of data to reserve for testing (default 0.2)
    input_file (str): Path to the input CSV (default: preprocessed/all_datasets_combined.csv)
    target_balance (float): Desired fraction of positives (e.g., 0.5 for 50% -> default: 0.5)
    balance_tolerance (float): Allowed deviation from the target balance (e.g., 0.05 for ±5% -> default: 0.05)

If the requested configuration (i.e. sample size and balance) isn’t possible, the code will search downward to use the largest possible number of rows that satisfies the configuration. After splitting, it reports the percentage of positive and negative samples in both train and test sets (using p_label as the balance metric in all cases).




example usage
python3 create_train_test_sets.py \
    --output_name trial_one \
    --num_rows 5000 \
    --origins 0 3 4 \
    --data_type phishing \
    --test_size 0.25 \
    --input_file preprocessed/all_datasets_combined.csv \
    --target_balance 0.5 \
    --balance_tolerance 0.05


In script (for these the __main__ needs to be commented):

filter_and_split_dataset(
    output_name="phishing_trial_a",
    num_rows=5000,
    origins=[0, 3, 4],
    data_type="phishing",
    test_size=0.25,
    input_file="preprocessed/all_datasets_combined.csv",
    target_balance=0.5,
    balance_tolerance=0.05
)
